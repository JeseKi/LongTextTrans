{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: \n",
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content='你', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: 你\n",
      "{'message': True, 'content': '你'}\n",
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content='好', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: 好\n",
      "{'message': True, 'content': '好'}\n",
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content='世', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: 世\n",
      "{'message': True, 'content': '世'}\n",
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content='界', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: 界\n",
      "{'message': True, 'content': '界'}\n",
      "Full chunk data: ChatCompletionChunk(id='chatcmpl-8UbJce4zPuVjWc9wq8bCaIAS9FdlR', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0)], created=1702303972, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
      "Extracted content: None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import OpenAI , OpenAIError\n",
    "\n",
    "def _openai_translate(api_keys,\n",
    "                            text: str, \n",
    "                            source_lang:str,\n",
    "                            target_lang: str, \n",
    "                            model: str) -> dict:\n",
    "    \n",
    "    time.sleep(0)\n",
    "    for api_key in api_keys:\n",
    "        try:\n",
    "            client = OpenAI(api_key=api_key)\n",
    "            stream = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {'role': 'system', 'content': 'You are a professional, authentic translation engine, only returns translations.'},\n",
    "                    {'role': 'user', 'content': f'Translate the text from {source_lang} to {target_lang} Language, please do not explain my original text.:{text}'}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                stream=True\n",
    "            )\n",
    "            isReponsed = True\n",
    "            \n",
    "            for chunk in stream:\n",
    "                print(\"Full chunk data:\", chunk)\n",
    "                if hasattr(chunk.choices[0].delta, 'content'):\n",
    "                    content = chunk.choices[0].delta.content  # Directly access the content attribute\n",
    "                    print(\"Extracted content:\", content)\n",
    "                    if content:\n",
    "                        yield {\n",
    "                            'message': isReponsed,\n",
    "                            'content': content\n",
    "                        }\n",
    "                else:\n",
    "                    print(\"Chunk does not have content attribute\")\n",
    "\n",
    "\n",
    "                    break\n",
    "\n",
    "        except OpenAIError as e:\n",
    "            yield(f\"An error occurred with key {api_key}: {str(e)}\\n\")\n",
    "\n",
    "\n",
    "for result in _openai_translate(['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'], \"Hello World\", 'en', 'zh', 'gpt-3.5-turbo'):\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
